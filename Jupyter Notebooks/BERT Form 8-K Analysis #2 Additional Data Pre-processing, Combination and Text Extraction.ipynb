{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import in dataset\n",
    "df = pd.read_csv('F:\\Files from Linux/textcorpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import in dataset with the key statistics from the quarterly/annual reports\n",
    "dfks = pd.read_csv('F:\\Files from Linux/keystatistics.csv')\n",
    "dfks['Quarter end'] = pd.to_datetime(dfks['Quarter end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify for row of our main dataset, which report for that ticker was the most recently available when the 8-K was released\n",
    "a = []\n",
    "b =[]\n",
    "for i, row in df.iterrows():\n",
    "    select = dfks[(dfks['ticker'] == row['ticker']) & (dfks['Quarter end'] < row['release_date_day'])]\n",
    "    b = select['Quarter end'].max()\n",
    "    a.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in identified date to main dataframe to join\n",
    "df['join date'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge dataset now that we know the proper date, on the date and ticker matching\n",
    "#Note that some tickers did not have historical key statistics available from the source I used.\n",
    "df = pd.merge(left=df, right = dfks, how ='left', left_on=['ticker','join date'], right_on=['ticker','Quarter end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify which items are contained in the 8-K\n",
    "df['item'] = \"\"\n",
    "\n",
    "#I realize it would have been best practices to define a function that would do this, but with copy/paste\n",
    "#it actually didn't take that much longer.\n",
    "\n",
    "#Section 1\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Entry into a Material Definitive Agreement'), \"Item 1.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Termination of a Material Definitive Agreement'), \"Item 1.02 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Bankruptcy or Receivership'), \"Item 1.03 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Mine Safety - Reporting of Shutdowns and Patterns of Violations'), \"Item 1.04 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "\n",
    "\n",
    "#Section 2\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Completion of Acquisition or Disposition of Assets'), \"Item 2.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Results of Operations and Financial Condition'), \"Item 2.02 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Creation of a Direct Financial Obligation or an Obligation under an Off-Balance Sheet Arrangement of a Registrant'), \"Item 2.03 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Triggering Events That Accelerate or Increase a Direct Financial Obligation or an Obligation under an Off-Balance Sheet Arrangement'), \"Item 2.04 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Associated with Exit or Disposal Activities'), \"Item 2.05 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Material Impairments'), \"Item 2.06 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "\n",
    "#Section 3\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Notice of Delisting or Failure to Satisfy a Continued Listing Rule or Standard; Transfer of Listing'), \"Item 3.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Unregistered Sales of Equity Securities'), \"Item 3.02 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Material Modification to Rights of Security Holders'), \"Item 3.03 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "\n",
    "#Section 4\n",
    "df['tempitem'] = np.where(df['text'].str.contains(\"Changes in Registrant's Certifying Accountant\"), \"Item 4.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Non-Reliance on Previously Issued Financial Statements or a Related Audit Report or Completed Interim Review'), \"Item 4.02 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "#Section 5\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Changes in Control of Registrant'), \"Item 5.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Departure of Directors or Certain Officers'), \"Item 5.02 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Amendments to Articles of Incorporation or Bylaws'), \"Item 5.03 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains(\"Temporary Suspension of Trading Under Registrant's Employee Benefit Plans\"), \"Item 5.04 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains(\"Amendment to Registrant's Code of Ethics, or Waiver of a Provision of the Code of Ethics\"), \"Item 5.05 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Change in Shell Company Status'), \"Item 5.06 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Submission of Matters to a Vote of Security Holders'), \"Item 5.07 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains(\"Shareholder Director Nominations\"), \"Item 5.08 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "\n",
    "#Section 6\n",
    "df['tempitem'] = np.where(df['text'].str.contains('ABS Informational and Computational Material'), \"Item 6.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Change of Servicer or Trustee'), \"Item 6.02 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Change in Credit Enhancement or Other External Support'), \"Item 6.03 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Failure to Make a Required Distribution'), \"Item 6.04 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Securities Act Updating Disclosure'), \"Item 6.05 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "#Section 7\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Regulation FD Disclosure'), \"Item 7.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "#Section 8\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Other Events'), \"Item 8.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "#Section 9\n",
    "\n",
    "df['tempitem'] = np.where(df['text'].str.contains('Financial Statements and Exhibits'), \"Item 9.01 \",\"\")\n",
    "df['item'] = df['item'] +  df['tempitem']\n",
    "\n",
    "df = df.drop(['tempitem'],axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove text and then save to csv for light weight data exploration.  \n",
    "df2 = df.drop(['text'],axis = 1)\n",
    "df2.to_csv(\"F:\\Files from Linux\\explorationdataset.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(s):\n",
    "    a = s.split(' ')\n",
    "    return len(a)\n",
    "\n",
    "df['text_len'] = df['text'].map(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this section i find the relevant text I wish to include.\n",
    "#After looking at Babbe's work I disagreed with the way that they found the text, as I believe it captures a great deal\n",
    "#of repetitiave language that doesn't actually help.\n",
    "#I found that searching for the listing market of NYSE or NASDAQ gets the press release if that was the report\n",
    "#Otherwise, useful text follows \"On January ....\" or other months of course.\n",
    "#The below code splits the text based on the phrase, and then keeps it if it was the earliest hit on a reg ex so far\n",
    "#Judging based on the length of the first portion of the split.\n",
    "\n",
    "#I realize this could have been done with a function, but with copy/pasting it didn't take very long anyway.\n",
    "\n",
    "#Tag lets us know which reg ex it used to extract text\n",
    "temp = df[\"text\"].str.split(\"On January \", n = 2, expand = True) \n",
    "temp['tag'] = 'jan'\n",
    "temp['textorig'] = df['text']\n",
    "temp['item'] = df['item']\n",
    "temp['ticker'] = df['ticker']\n",
    "temp['origlen'] = df['text_len']\n",
    "temp['len'] = df['text_len']\n",
    "temp['newesttext'] = temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On February \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'feb', temp['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On March \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'mar', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On April \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'April', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On May \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'May', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On June \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'June', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On July \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'July', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On August \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'August', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On September \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'September', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On October \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'October', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On November \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'November', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"On December \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'December', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after reviewing the outcome of the above about 10k of the 20k had results returned.\n",
    "#some of the remaining have under 400 words, which is a good indication that it is entirely boilerplate\n",
    "#However, some more searches were found that could help.\n",
    "#Got another 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"today provided\", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'today', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"as of \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'as of', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"Other events.\", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'other events', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"held on \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['len'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['len'], 'held on', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['len'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"NYSE: \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['origlen'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['origlen'], 'NYSE', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['origlen'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[\"text\"].str.split(\"NASDAQ: \", n = 2, expand = True) \n",
    "temp1['len'] = temp1[0].map(word_count)\n",
    "temp1['newesttext'] = temp1[1]\n",
    "temp['newesttext'] = np.where(temp1['len'] < temp['origlen'], temp1['newesttext'], temp['newesttext'])\n",
    "temp['tag'] = np.where(temp1['len'] < temp['origlen'], 'NASDAQ', temp['tag'])\n",
    "temp['len'] = np.where(temp1['len'] < temp['origlen'], temp1['len'], temp['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19451\n"
     ]
    }
   ],
   "source": [
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9099\n"
     ]
    }
   ],
   "source": [
    "#Look at all examples where no text was extracted\n",
    "#Total of 9099\n",
    "temp1 = temp\n",
    "bool_series = pd.isnull(temp1[\"newesttext\"])  \n",
    "textfailed = temp1[bool_series]  \n",
    "textfailed = temp1[bool_series]  \n",
    "print(len(textfailed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702\n"
     ]
    }
   ],
   "source": [
    "#Remove all examples where the text is less than 600 or more than 10,000\n",
    "#Save files to take a look\n",
    "#See how are remaining\n",
    "#this represents the total number where we could probably extract text from but haven't\n",
    "#702 fit this criteria, so were at diminishing returns\n",
    "textfailed2 = textfailed[textfailed['origlen'] > 600]\n",
    "textfailed2 = textfailed2[textfailed2['origlen'] < 10000]\n",
    "textfailed2.to_csv(\"F:\\Files from Linux/failedtexts2.csv\",header=True)\n",
    "print(len(textfailed2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6773\n"
     ]
    }
   ],
   "source": [
    "#Do the same text legnth cull for the ones where we did find a result\n",
    "#save it for exploration\n",
    "#Total of 6,773 remaining\n",
    "temp1 = temp[-bool_series]  \n",
    "temp1 = temp1[temp1['origlen'] > 600]\n",
    "temp1 = temp1[temp1['origlen'] < 10000]\n",
    "temp1.to_csv(\"F:\\Files from Linux/gooddata.csv\",header=True)\n",
    "print(len(temp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join text to main dataframe\n",
    "df['cleantext'] = temp['newesttext']\n",
    "df['cleantextlen'] = temp['len']\n",
    "df['tag'] = temp['tag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save full dataset\n",
    "df.to_csv(\"F:\\Files from Linux/fulldataset.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove text, remove rows based on text length, remove rows where no clean text is found\n",
    "bool_series = pd.isnull(df[\"cleantext\"])  \n",
    "df = df[-bool_series]  \n",
    "df = df[df['text_len'] > 600]\n",
    "df = df.drop(['text'],axis = 1)\n",
    "df['cleantext'] = df['cleantext'].str[:50000]\n",
    "df.to_csv(\"F:\\Files from Linux/cleaneddataset.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://DESKTOP-Q733R8K:40000/dtale/main/1\n",
      "It looks like this data may have already been loaded to D-Tale based on shape and column names. Here is URL of the data that seems to match it:\n",
      "\n",
      "None\n",
      "\n",
      "If you still want to load this data please use the following command:\n",
      "\n",
      "dtale.show(df, ignore_duplicate=True)\n",
      "Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-06 19:16:04,583 - INFO     - Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-06 19:16:08,620 - INFO     - Executing shutdown...\n"
     ]
    }
   ],
   "source": [
    "import dtale\n",
    "\n",
    "d = dtale.show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://DESKTOP-Q733R8K:40000/dtale/main/1\n",
      "It looks like this data may have already been loaded to D-Tale based on shape and column names. Here is URL of the data that seems to match it:\n",
      "\n",
      "None\n",
      "\n",
      "If you still want to load this data please use the following command:\n",
      "\n",
      "dtale.show(df, ignore_duplicate=True)\n"
     ]
    }
   ],
   "source": [
    "import dtale\n",
    "\n",
    "d = dtale.show(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model (a majority of this code is copied from the BERT Tutorial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
